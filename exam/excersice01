Import employee database to mysql from - http://dev.mysql.com/doc/employee/en/

task#1 :
There is a employee database in mysql. Import all the tables from employee database into HDFS. 
Save all table data in  warehouse directory '/user/hive/warehouse' 
Tables should be accessible via hive 
table data should be comma separated format.

Following tables should get imported successfully.
+---------------------+
| Tables_in_employees |
+---------------------+
| departments         |
| dept_emp            |
| dept_manager        |
| employees           |
| salaries            |
| titles              |
+---------------------+

Concepts Covered : Sqoop import, Hive Database 


task#2:
There is a employee database in mysql. Import table employees in HDFS in 'solution' database in hive.
Save all table data in  warehouse directory '/user/hive/warehouse' 
Tables should be accessible via hive 
table data should be tab separated format.

Concepts Covered : Sqoop Import, data modification

task#3 : 

Write a python script to read employee data from warehouse. Modify data to be tab separated instead of comma separated
and save results in '/user/cloudera/solution3'
A template of program is provided in '/home/cloudera/task03' directory in task03.py. You may use run.sh to execute the script

Concepts Covered : Pyspark, map, saveAsTextFiles,python,spark-submit

Task#04 :

Write scala script to find the employees whose title is 'Senior Engineer' and salary is in range '$75,000 - $100,000'. 
Save the results in '/user/cloudera/solution4'
A template of program is provided in '/home/cloudera/task04' directory in task03.py. You may use run.sh to execute the script

Output should be in following format -

employeeID,title,salary


Concepts Covered : spark-shell,spark-submit,Scala,map,filter,join

Task05 : 

Write a python script to find the average salary of female employees and male employees.

Concepts Covered : pyspark,python,map,filter,aggregateByKey,reduceByKey

Task06 :
Write a scala/python script to find the employees who had largest increament in salary since they joined the company.

Concepts Covered : pyspark,passing function to spark, map,filter, sortBy()


Task07 : 
This depends on data generated from task 03. Create a employee table in hive database solution7 which when 
queried on will perform faster when separated by a new columns 'hire-year' and 'hire-month'. Table data should recide in 
'/user/cloudera/employees_partitioned'

Concepts Covered : Hive DDL,paritioning, create external, insert


Task08: 

Convert all tables (from task01 )in which are stored in comma separated format in /user/hive/warehouse to json and 
store json data in /user/cloudera/employees_json/










